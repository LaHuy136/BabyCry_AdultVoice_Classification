{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pyaudio\n",
    "import wave\n",
    "from hmmlearn.hmm import GMMHMM\n",
    "from pydub import AudioSegment\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(file_path):\n",
    "    y, sr = librosa.load(file_path) \n",
    "    hop_length = math.floor(sr * 0.015)  # 10ms hop\n",
    "    win_length = math.floor(sr * 0.030)  # 25ms frame\n",
    "\n",
    "    # Trích xuất MFCC\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y=y, sr=sr, n_mfcc=12, n_fft=1024,\n",
    "        hop_length=hop_length, win_length=win_length)\n",
    "    \n",
    "    # Trích xuất thành phần năng lượng và khớp kích thước\n",
    "    energy = librosa.feature.rms(y=y, frame_length=win_length, hop_length=hop_length)\n",
    "    if energy.shape[1] < mfcc.shape[1]:\n",
    "        energy = np.pad(energy, ((0, 0), (0, mfcc.shape[1] - energy.shape[1])), mode='constant')\n",
    "    elif energy.shape[1] > mfcc.shape[1]:\n",
    "        mfcc = np.pad(mfcc, ((0, 0), (0, energy.shape[1] - mfcc.shape[1])), mode='constant')\n",
    "\n",
    "    # Thêm thành phần năng lượng vào MFCC\n",
    "    mfcc = np.vstack((mfcc, energy))\n",
    "\n",
    "    # Chuẩn hóa MFCC bằng cách trừ đi giá trị trung bình\n",
    "    mfcc = mfcc - np.mean(mfcc, axis=1).reshape((-1, 1))\n",
    "    \n",
    "    # Tính các hệ số delta và acceleration\n",
    "    delta1 = librosa.feature.delta(mfcc, order=1)  # Đạo hàm bậc 1\n",
    "    delta2 = librosa.feature.delta(mfcc, order=2)  # Đạo hàm bậc 2\n",
    "    \n",
    "    # Gộp MFCC, delta1, và delta2 lại thành một ma trận\n",
    "    X = np.concatenate([mfcc, delta1, delta2], axis=0)  # Kết quả là ma trận (số đặc trưng, số khung)\n",
    "    \n",
    "    # Kết quả sẽ có kích thước (số khung, 39), phù hợp với định dạng mà hmmlearn yêu cầu (T x N), \n",
    "    # trong đó \n",
    "        # T là số khung thời gian\n",
    "        # N là số đặc trưng\n",
    "    return X.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMMTraining:\n",
    "    def __init__(self):\n",
    "        self.class_names = ['baby cry', 'adult voice']\n",
    "        \n",
    "        self.states = [5, 5, 5] # n_components\n",
    "        self.mix=2 # n_mix\n",
    "        \n",
    "        self.dataset_path = 'data_bbcry_or_not'\n",
    "\n",
    "        self.X = {'train': {}, 'test': {}}\n",
    "        self.y = {'train': {}, 'test': {}}\n",
    "\n",
    "        self.model = {}\n",
    "        self.model_path = 'models_train'\n",
    "        self.loss_history = {cname: [] for cname in self.class_names}\n",
    "\n",
    "    def train(self):\n",
    "        length = 0\n",
    "        for cn in self.class_names:\n",
    "            length += len(os.listdir(f\"{self.dataset_path}/{cn}\"))\n",
    "        print('Total samples:', length)  # Total samples\n",
    "\n",
    "        all_data = {}\n",
    "        all_labels = {}\n",
    "        for cname in self.class_names:\n",
    "            file_paths = [os.path.join(self.dataset_path, cname, i) for i in os.listdir(\n",
    "                os.path.join(self.dataset_path, cname)) if i.endswith('.wav')]\n",
    "            data = [get_mfcc(file_path) for file_path in file_paths]\n",
    "            all_data[cname] = data\n",
    "            all_labels[cname] = [self.class_names.index(cname) for _ in range(len(file_paths))]\n",
    "\n",
    "        for cname in self.class_names:\n",
    "            x_train, x_test, y_train, y_test = train_test_split(\n",
    "                all_data[cname], all_labels[cname],\n",
    "                test_size=0.3,  # 70% testing, 30% traing\n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "            self.X['train'][cname] = x_train\n",
    "            self.X['test'][cname] = x_test\n",
    "            self.y['test'][cname] = y_test\n",
    "\n",
    "        total_train = 0\n",
    "        total_test = 0\n",
    "        for cname in self.class_names:\n",
    "            train_count = len(self.X['train'][cname])\n",
    "            test_count = len(self.X['test'][cname])\n",
    "            print(cname, 'train:', train_count, '| test:', test_count)  # Print cothe train: total | test: total\n",
    "                                                                        #       khong train: total | test: total\n",
    "                                                                        #       nhung train: total | test: total\n",
    "            total_train += train_count\n",
    "            total_test += test_count\n",
    "        print('train samples:', total_train) # Total Train\n",
    "        print('test samples', total_test) # Total test\n",
    "\n",
    "        for idx, cname in enumerate(self.class_names):\n",
    "            start_prob = np.full(self.states[idx], 0.0)\n",
    "            start_prob[1] = 1.0 # prob of state init\n",
    "            trans_matrix = np.full((self.states[idx], self.states[idx]), 0.0)\n",
    "            p = 0.5 # Giá trị này xác định xác suất chuyển tiếp nội bộ giữa các trạng thái\n",
    "            np.fill_diagonal(trans_matrix, p)\n",
    "            np.fill_diagonal(trans_matrix[0:, 1:], 1 - p)\n",
    "            trans_matrix[-1, -1] = 1.0\n",
    "            \n",
    "            trans_matrix = trans_matrix / 6\n",
    "\n",
    "            # trans matrix\n",
    "            print(cname)\n",
    "            print(trans_matrix)\n",
    "\n",
    "            self.model[cname] = GMMHMM(\n",
    "                n_components=self.states[idx], \n",
    "                n_mix=self.mix, \n",
    "                startprob_prior=start_prob, \n",
    "                transmat_prior=trans_matrix,\n",
    "                algorithm='viterbi', \n",
    "                random_state=42,\n",
    "                n_iter=300, \n",
    "                verbose=True, \n",
    "                params='stmc', \n",
    "                init_params='mc'\n",
    "            )\n",
    "            # Traning and save loss (Baum-Welch Algorithm)\n",
    "            self.model[cname].fit(X=np.vstack(self.X['train'][cname]), \n",
    "                                  lengths=[x.shape[0] for x in self.X['train'][cname]])\n",
    "            self.loss_history[cname] = self.model[cname].monitor_.history \n",
    "\n",
    "    def save_model(self):\n",
    "        for cname in self.class_names:\n",
    "            name = f'{self.model_path}/model_{cname}.pkl'\n",
    "            with open(name, 'wb') as file:\n",
    "                pickle.dump(self.model[cname], file)\n",
    "\n",
    "    def evaluation(self):\n",
    "        print('====== Evaluation ======')\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        for cname in self.class_names:\n",
    "            for mfcc, target in zip(self.X['test'][cname], self.y['test'][cname]):\n",
    "                # Tính điểm cho từng lớp\n",
    "                scores = [self.model[cls].score(mfcc) for cls in self.class_names]\n",
    "                pred = np.argmax(scores)  \n",
    "                y_pred.append(pred)\n",
    "                y_true.append(self.class_names.index(cname))  # Gán nhãn đúng với chỉ số lớp hiện tại\n",
    "\n",
    "        # In tỷ lệ chính xác cho từng lớp\n",
    "        for i, cname in enumerate(self.class_names):\n",
    "            class_correct = [\n",
    "                1 for yt, yp in zip(y_true, y_pred) if yt == yp and yt == i\n",
    "            ]\n",
    "            class_total = y_true.count(i)\n",
    "            accuracy = len(class_correct) / class_total if class_total > 0 else 0.0\n",
    "            print(f'{cname}: {accuracy:.2%}')\n",
    "        print('======')\n",
    "         # Tính các chỉ số\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "\n",
    "        print(f\"  - Accuracy: {accuracy:.6%}\")\n",
    "        print(f\"  - Precision: {precision:.6%}\")\n",
    "        print(f\"  - Recall: {recall:.6%}\")\n",
    "        print(f\"  - F1-score: {f1:.6%}\")\n",
    "        print('======')\n",
    "        print('Confusion matrix:')\n",
    "        print(confusion_matrix(y_true, y_pred))\n",
    "        \n",
    "    def plot_loss(self): \n",
    "        for cname in self.class_names: \n",
    "            plt.plot(self.loss_history[cname], label=f'{cname}') \n",
    "        plt.xlabel('Iteration') \n",
    "        plt.ylabel('Log Likelihood') \n",
    "        plt.title('Training Loss') \n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    hmm_train = HMMTraining()\n",
    "    hmm_train.train()\n",
    "    hmm_train.save_model()\n",
    "    hmm_train.evaluation()\n",
    "    # hmm_train.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores [-60879.59379789139, -64185.74340881428]\n",
      "baby cry\n",
      "scores [-46260.98085829911, -53144.4823782904]\n",
      "baby cry\n",
      "scores [-22439.455237114646, -23995.617812944976]\n",
      "baby cry\n"
     ]
    }
   ],
   "source": [
    "class HMMRecognition:\n",
    "    def __init__(self):\n",
    "        self.model = {}\n",
    "\n",
    "        self.class_names = ['baby cry', 'adult voice']\n",
    "       \n",
    "        self.audio_format = 'wav'\n",
    "\n",
    "        self.record_path = 'temp/record.wav'\n",
    "        self.trimmed_path = 'temp/trimmed.wav'\n",
    "        self.model_path = 'models_train/5-2-39'\n",
    "\n",
    "        self.load_model()\n",
    "\n",
    "    @staticmethod\n",
    "    def detect_leading_silence(sound, silence_threshold=-42.0, chunk_size=10):\n",
    "        trim_ms = 0  # ms\n",
    "\n",
    "        assert chunk_size > 0  # to avoid infinite loop\n",
    "        while sound[trim_ms:trim_ms + chunk_size].dBFS < silence_threshold and trim_ms < len(sound):\n",
    "            trim_ms += chunk_size\n",
    "\n",
    "        return trim_ms\n",
    "\n",
    "    def load_model(self):\n",
    "        for key in self.class_names:\n",
    "            name = f\"{self.model_path}/model_{key}.pkl\"\n",
    "            with open(name, 'rb') as file:\n",
    "                self.model[key] = pickle.load(file)\n",
    "\n",
    "    def predict(self, file_name=None):\n",
    "        if not file_name:\n",
    "            file_name = self.record_path\n",
    "\n",
    "        os.makedirs(os.path.dirname(self.trimmed_path), exist_ok=True)\n",
    "        \n",
    "        # Trim silence\n",
    "        sound = AudioSegment.from_file(file_name, format=self.audio_format)\n",
    "\n",
    "        start_trim = self.detect_leading_silence(sound)\n",
    "        end_trim = self.detect_leading_silence(sound.reverse())\n",
    "\n",
    "        duration = len(sound)\n",
    "\n",
    "        trimmed_sound = sound[start_trim:duration - end_trim]\n",
    "        trimmed_sound.export(self.trimmed_path, format=self.audio_format)\n",
    "\n",
    "        # Predict\n",
    "        record_mfcc = get_mfcc(self.trimmed_path)\n",
    "        scores = [self.model[cname].score(record_mfcc) for cname in self.class_names]\n",
    "        print('scores', scores)\n",
    "        predict_word = np.argmax(scores)\n",
    "        print(self.class_names[predict_word])\n",
    "\n",
    "    def record(self):\n",
    "        CHUNK = 1024\n",
    "        FORMAT = pyaudio.paInt16\n",
    "        CHANNELS = 1\n",
    "        RATE = 16000\n",
    "        RECORD_SECONDS = 5\n",
    "\n",
    "        p = pyaudio.PyAudio()\n",
    "\n",
    "        stream = p.open(format=FORMAT,\n",
    "                        channels=CHANNELS,\n",
    "                        rate=RATE,\n",
    "                        input=True,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "\n",
    "        frames = []\n",
    "\n",
    "        print('recording ...')\n",
    "        for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "            data = stream.read(CHUNK)\n",
    "            frames.append(data)\n",
    "\n",
    "        print('stopped record!')\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "\n",
    "        wf = wave.open(self.record_path, 'wb')\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "        wf.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    hmm_reg = HMMRecognition()\n",
    "    hmm_reg.record()\n",
    "    hmm_reg.predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
